{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def pattern_matching(output_text):\n",
    "    \"\"\"\n",
    "    Extracts correctness and reasoning score from output_text using regex.\n",
    "    Handles both markdown-style (bold `**text:**`) and plain text formats.\n",
    "    \"\"\"\n",
    "    # Regex patterns to capture numbers and words after \"Reasoning Score:\" and \"Correctness:\"\n",
    "    reasoning_pattern = r'(?:\\*\\*Reasoning Score:\\*\\*|Reasoning Score:)\\s*(\\d+)'\n",
    "    correctness_pattern = r'(?:\\*\\*Correctness:\\*\\*|Correctness:)\\s*(\\w+)'\n",
    "\n",
    "    # Search for Reasoning Score\n",
    "    score_match = re.search(reasoning_pattern, output_text)\n",
    "    reasoning_score = int(score_match.group(1)) if score_match else 0  # Return 0 instead of NaN\n",
    "\n",
    "    # Search for Correctness\n",
    "    correctness_match = re.search(correctness_pattern, output_text)\n",
    "    correctness = correctness_match.group(1) if correctness_match else \"unknown\"  # Default to \"unknown\" if missing\n",
    "\n",
    "    return correctness, reasoning_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:32<06:08, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_14b_judge_llama_3_1_8B_it_attack_alter.csv\n",
      "len(df): 193\n",
      "correctness_acc: 96.37305699481865\n",
      "easy_acc: 98.33333333333333\n",
      "med_acc: 97.32142857142857\n",
      "hard_acc: 85.71428571428571\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.694300518134715\n",
      "avg_easy_reasoning_score: 4.633333333333334\n",
      "avg_med_reasoning_score: 4.741071428571429\n",
      "avg_hard_reasoning_score: 4.619047619047619\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:48<05:52, 16.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_14b_judge_llama_3_1_8B_it_attack_irrelevant.csv\n",
      "len(df): 235\n",
      "correctness_acc: 100.0\n",
      "easy_acc: 100.0\n",
      "med_acc: 100.0\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.965957446808511\n",
      "avg_easy_reasoning_score: 4.955223880597015\n",
      "avg_med_reasoning_score: 4.978260869565218\n",
      "avg_hard_reasoning_score: 4.931034482758621\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [01:10<06:28, 18.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_14b_judge_llama_3_1_8B_it_attack_naive.csv\n",
      "len(df): 271\n",
      "correctness_acc: 99.63099630996311\n",
      "easy_acc: 100.0\n",
      "med_acc: 99.37888198757764\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.974169741697417\n",
      "avg_easy_reasoning_score: 5.0\n",
      "avg_med_reasoning_score: 4.968944099378882\n",
      "avg_hard_reasoning_score: 4.948717948717949\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [01:48<08:26, 25.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_14b_judge_llama_3_1_8B_it_attack_paraphrase.csv\n",
      "len(df): 269\n",
      "correctness_acc: 96.6542750929368\n",
      "easy_acc: 95.71428571428572\n",
      "med_acc: 98.10126582278481\n",
      "hard_acc: 92.5\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.921933085501859\n",
      "avg_easy_reasoning_score: 4.8428571428571425\n",
      "avg_med_reasoning_score: 4.981012658227848\n",
      "avg_hard_reasoning_score: 4.825\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [02:02<06:44, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_32b_judge_llama_3_1_8B_it_attack_alter.csv\n",
      "len(df): 204\n",
      "correctness_acc: 97.05882352941177\n",
      "easy_acc: 95.08196721311475\n",
      "med_acc: 97.45762711864407\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.745098039215686\n",
      "avg_easy_reasoning_score: 4.672131147540983\n",
      "avg_med_reasoning_score: 4.762711864406779\n",
      "avg_hard_reasoning_score: 4.875\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [02:20<06:07, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_32b_judge_llama_3_1_8B_it_attack_irrelevant.csv\n",
      "len(df): 274\n",
      "correctness_acc: 98.54014598540147\n",
      "easy_acc: 100.0\n",
      "med_acc: 98.10126582278481\n",
      "hard_acc: 97.77777777777777\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.916058394160584\n",
      "avg_easy_reasoning_score: 4.942857142857143\n",
      "avg_med_reasoning_score: 4.8924050632911396\n",
      "avg_hard_reasoning_score: 4.955555555555556\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [02:41<05:47, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_32b_judge_llama_3_1_8B_it_attack_naive.csv\n",
      "len(df): 286\n",
      "correctness_acc: 99.3006993006993\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 99.41176470588235\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.937062937062937\n",
      "avg_easy_reasoning_score: 4.9\n",
      "avg_med_reasoning_score: 4.9411764705882355\n",
      "avg_hard_reasoning_score: 4.977777777777778\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [03:01<05:27, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_32b_judge_llama_3_1_8B_it_attack_paraphrase.csv\n",
      "len(df): 289\n",
      "correctness_acc: 98.26989619377161\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 98.22485207100591\n",
      "hard_acc: 97.95918367346938\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.882352941176471\n",
      "avg_easy_reasoning_score: 4.9714285714285715\n",
      "avg_med_reasoning_score: 4.846153846153846\n",
      "avg_hard_reasoning_score: 4.877551020408164\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [03:08<04:02, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_7b_judge_llama_3_1_8B_it_attack_alter.csv\n",
      "len(df): 130\n",
      "correctness_acc: 93.84615384615384\n",
      "easy_acc: 91.30434782608695\n",
      "med_acc: 93.84615384615384\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.630769230769231\n",
      "avg_easy_reasoning_score: 4.565217391304348\n",
      "avg_med_reasoning_score: 4.6\n",
      "avg_hard_reasoning_score: 4.888888888888889\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [03:16<03:15, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_7b_judge_llama_3_1_8B_it_attack_irrelevant.csv\n",
      "len(df): 195\n",
      "correctness_acc: 99.48717948717949\n",
      "easy_acc: 100.0\n",
      "med_acc: 99.11504424778761\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.9282051282051285\n",
      "avg_easy_reasoning_score: 4.982456140350878\n",
      "avg_med_reasoning_score: 4.902654867256637\n",
      "avg_hard_reasoning_score: 4.916666666666667\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [03:25<02:40, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_7b_judge_llama_3_1_8B_it_attack_naive.csv\n",
      "len(df): 194\n",
      "correctness_acc: 99.48453608247422\n",
      "easy_acc: 100.0\n",
      "med_acc: 99.09909909909909\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.938144329896907\n",
      "avg_easy_reasoning_score: 4.967213114754099\n",
      "avg_med_reasoning_score: 4.936936936936937\n",
      "avg_hard_reasoning_score: 4.857142857142857\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [03:34<02:14, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_deepseek_7b_judge_llama_3_1_8B_it_attack_paraphrase.csv\n",
      "len(df): 194\n",
      "correctness_acc: 99.48453608247422\n",
      "easy_acc: 98.4126984126984\n",
      "med_acc: 100.0\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.963917525773196\n",
      "avg_easy_reasoning_score: 4.968253968253968\n",
      "avg_med_reasoning_score: 4.972477064220183\n",
      "avg_hard_reasoning_score: 4.904761904761905\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [03:40<01:46,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_llama_3_1_8B_it_judge_llama_3_1_8B_it_attack_alter.csv\n",
      "len(df): 300\n",
      "correctness_acc: 96.66666666666667\n",
      "easy_acc: 95.71428571428572\n",
      "med_acc: 96.53179190751445\n",
      "hard_acc: 98.21428571428571\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.773333333333333\n",
      "avg_easy_reasoning_score: 4.757142857142857\n",
      "avg_med_reasoning_score: 4.77456647398844\n",
      "avg_hard_reasoning_score: 4.785714285714286\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [03:46<01:26,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_llama_3_1_8B_it_judge_llama_3_1_8B_it_attack_irrelevant.csv\n",
      "len(df): 300\n",
      "correctness_acc: 99.0\n",
      "easy_acc: 100.0\n",
      "med_acc: 99.42196531791907\n",
      "hard_acc: 96.42857142857143\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.913333333333333\n",
      "avg_easy_reasoning_score: 4.928571428571429\n",
      "avg_med_reasoning_score: 4.92485549132948\n",
      "avg_hard_reasoning_score: 4.857142857142857\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [03:55<01:18,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_llama_3_1_8B_it_judge_llama_3_1_8B_it_attack_naive.csv\n",
      "len(df): 300\n",
      "correctness_acc: 99.0\n",
      "easy_acc: 100.0\n",
      "med_acc: 98.26589595375722\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.9\n",
      "avg_easy_reasoning_score: 4.885714285714286\n",
      "avg_med_reasoning_score: 4.913294797687861\n",
      "avg_hard_reasoning_score: 4.875\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [04:02<01:05,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_llama_3_1_8B_it_judge_llama_3_1_8B_it_attack_paraphrase.csv\n",
      "len(df): 300\n",
      "correctness_acc: 99.33333333333333\n",
      "easy_acc: 97.14285714285714\n",
      "med_acc: 100.0\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.883333333333334\n",
      "avg_easy_reasoning_score: 4.928571428571429\n",
      "avg_med_reasoning_score: 4.861271676300578\n",
      "avg_hard_reasoning_score: 4.892857142857143\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [04:09<00:55,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwen_2_5_7b_judge_llama_3_1_8B_it_attack_alter.csv\n",
      "len(df): 300\n",
      "correctness_acc: 95.66666666666667\n",
      "easy_acc: 88.57142857142857\n",
      "med_acc: 98.84393063583815\n",
      "hard_acc: 94.64285714285714\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.626666666666667\n",
      "avg_easy_reasoning_score: 4.571428571428571\n",
      "avg_med_reasoning_score: 4.6531791907514455\n",
      "avg_hard_reasoning_score: 4.607142857142857\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [04:16<00:45,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwen_2_5_7b_judge_llama_3_1_8B_it_attack_irrelevant.csv\n",
      "len(df): 300\n",
      "correctness_acc: 97.33333333333334\n",
      "easy_acc: 94.28571428571428\n",
      "med_acc: 98.84393063583815\n",
      "hard_acc: 96.42857142857143\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.753333333333333\n",
      "avg_easy_reasoning_score: 4.685714285714286\n",
      "avg_med_reasoning_score: 4.791907514450867\n",
      "avg_hard_reasoning_score: 4.714285714285714\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [04:22<00:36,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwen_2_5_7b_judge_llama_3_1_8B_it_attack_naive.csv\n",
      "len(df): 300\n",
      "correctness_acc: 98.33333333333333\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 98.26589595375722\n",
      "hard_acc: 98.21428571428571\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.8133333333333335\n",
      "avg_easy_reasoning_score: 4.771428571428571\n",
      "avg_med_reasoning_score: 4.791907514450867\n",
      "avg_hard_reasoning_score: 4.928571428571429\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [04:29<00:28,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwen_2_5_7b_judge_llama_3_1_8B_it_attack_paraphrase.csv\n",
      "len(df): 300\n",
      "correctness_acc: 96.66666666666667\n",
      "easy_acc: 95.71428571428572\n",
      "med_acc: 97.6878612716763\n",
      "hard_acc: 94.64285714285714\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.8\n",
      "avg_easy_reasoning_score: 4.771428571428571\n",
      "avg_med_reasoning_score: 4.815028901734104\n",
      "avg_hard_reasoning_score: 4.785714285714286\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [04:39<00:23,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwq_32b_judge_llama_3_1_8B_it_attack_alter.csv\n",
      "len(df): 289\n",
      "correctness_acc: 98.6159169550173\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 98.7878787878788\n",
      "hard_acc: 98.11320754716981\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.865051903114187\n",
      "avg_easy_reasoning_score: 4.857142857142857\n",
      "avg_med_reasoning_score: 4.878787878787879\n",
      "avg_hard_reasoning_score: 4.830188679245283\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [04:48<00:16,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwq_32b_judge_llama_3_1_8B_it_attack_irrelevant.csv\n",
      "len(df): 291\n",
      "correctness_acc: 97.59450171821305\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 97.0059880239521\n",
      "hard_acc: 98.11320754716981\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.962199312714777\n",
      "avg_easy_reasoning_score: 4.957142857142857\n",
      "avg_med_reasoning_score: 4.970059880239521\n",
      "avg_hard_reasoning_score: 4.943396226415095\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [04:55<00:07,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwq_32b_judge_llama_3_1_8B_it_attack_naive.csv\n",
      "len(df): 298\n",
      "correctness_acc: 97.6510067114094\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 96.51162790697676\n",
      "hard_acc: 100.0\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.939597315436242\n",
      "avg_easy_reasoning_score: 4.9\n",
      "avg_med_reasoning_score: 4.965116279069767\n",
      "avg_hard_reasoning_score: 4.909090909090909\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:09<00:00, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "csv_path: target_qwq_32b_judge_llama_3_1_8B_it_attack_paraphrase.csv\n",
      "len(df): 296\n",
      "correctness_acc: 99.32432432432432\n",
      "easy_acc: 98.57142857142858\n",
      "med_acc: 100.0\n",
      "hard_acc: 98.14814814814815\n",
      "\n",
      "\n",
      "avg_reasoning_score: 4.949324324324325\n",
      "avg_easy_reasoning_score: 4.942857142857143\n",
      "avg_med_reasoning_score: 4.941520467836257\n",
      "avg_hard_reasoning_score: 4.981481481481482\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "all_csv = 'all_results_reasoning.csv'\n",
    "results_df = pd.DataFrame(columns=['csv_path', 'len(df)', 'correctness_acc', 'easy_acc', 'med_acc', 'hard_acc', 'avg_reasoning_score', 'avg_easy_reasoning_score', 'avg_med_reasoning_score', 'avg_hard_reasoning_score'])\n",
    "\n",
    "csv_paths = glob.glob(\"*.csv\")\n",
    "for csv_path in tqdm(csv_paths):\n",
    "    if csv_path == all_csv:\n",
    "        continue\n",
    "\n",
    "    easy_corr_list, med_corr_list, hard_corr_list = [], [], []\n",
    "    easy_reas_list, med_reas_list, hard_reas_list = [], [], []\n",
    "\n",
    "    correctness_list = []\n",
    "    reasoning_scores = []\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for idx, row in df.iterrows():\n",
    "        difficulty = row['difficulty']\n",
    "        correctness = row['correctness']\n",
    "        reasoning_score = row['reasoning_score']\n",
    "        output_text = row['eval_result']\n",
    "        # print(f'{output_text}')\n",
    "\n",
    "        # if reasoning_score is None or math.isnan(reasoning_score):\n",
    "        correctness, reasoning_score = pattern_matching(output_text)\n",
    "        correctness_list.append(correctness)\n",
    "        reasoning_scores.append(reasoning_score)\n",
    "        if difficulty == 'Easy':\n",
    "            easy_corr_list.append(correctness)\n",
    "            easy_reas_list.append(reasoning_score)\n",
    "        elif difficulty == 'Medium':\n",
    "            med_corr_list.append(correctness)\n",
    "            med_reas_list.append(reasoning_score)\n",
    "        elif difficulty == 'Hard':\n",
    "            hard_corr_list.append(correctness)\n",
    "            hard_reas_list.append(reasoning_score)\n",
    "\n",
    "        df.at[idx, 'correctness'] = correctness\n",
    "        df.at[idx, 'reasoning_score'] = reasoning_score\n",
    "        df.to_csv(csv_path)\n",
    "\n",
    "        # print(f'correctness: {correctness}, {type(correctness)}')\n",
    "        # print(f'reasoning_score: {reasoning_score}, {type(reasoning_score)}')\n",
    "    \n",
    "    correctness_acc = (correctness_list.count('correct') / len(correctness_list)) * 100\n",
    "    easy_acc = (easy_corr_list.count('correct') / len(easy_corr_list)) * 100\n",
    "    med_acc = (med_corr_list.count('correct') / len(med_corr_list)) * 100\n",
    "    hard_acc = (hard_corr_list.count('correct') / len(hard_corr_list)) * 100\n",
    "\n",
    "    avg_reasoning_score = (sum(reasoning_scores) / len(reasoning_scores))\n",
    "    avg_easy_reasoning_score = (sum(easy_reas_list) / len(easy_reas_list))\n",
    "    avg_med_reasoning_score = (sum(med_reas_list) / len(med_reas_list))\n",
    "    avg_hard_reasoning_score = (sum(hard_reas_list) / len(hard_reas_list))\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"*\"*50)\n",
    "    print(f\"csv_path: {csv_path}\")\n",
    "    print(f\"len(df): {len(df)}\")\n",
    "    print(f\"correctness_acc: {correctness_acc}\")\n",
    "    print(f\"easy_acc: {easy_acc}\")\n",
    "    print(f\"med_acc: {med_acc}\")\n",
    "    print(f\"hard_acc: {hard_acc}\")\n",
    "    print('\\n')\n",
    "    print(f\"avg_reasoning_score: {avg_reasoning_score}\")\n",
    "    print(f\"avg_easy_reasoning_score: {avg_easy_reasoning_score}\")\n",
    "    print(f\"avg_med_reasoning_score: {avg_med_reasoning_score}\")\n",
    "    print(f\"avg_hard_reasoning_score: {avg_hard_reasoning_score}\")\n",
    "    print(\"*\"*50)\n",
    "    print('\\n')\n",
    "\n",
    "    new_row = {\n",
    "        \"csv_path\": csv_path,\n",
    "        \"len(df)\": len(df),\n",
    "        \"correctness_acc\": correctness_acc,\n",
    "        \"easy_acc\": easy_acc,\n",
    "        \"med_acc\": med_acc,\n",
    "        \"hard_acc\": hard_acc,\n",
    "        \"avg_reasoning_score\": avg_reasoning_score,\n",
    "        \"avg_easy_reasoning_score\": avg_easy_reasoning_score,\n",
    "        \"avg_med_reasoning_score\": avg_med_reasoning_score,\n",
    "        \"avg_hard_reasoning_score\": avg_hard_reasoning_score,\n",
    "    }\n",
    "\n",
    "    new_idx = len(results_df)\n",
    "    results_df.loc[new_idx] = new_row\n",
    "    results_df.to_csv(all_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
