/work/pi_ahoumansadr_umass_edu/jroh/miniconda3/envs/overthink/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:29<00:29, 29.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:51<00:00, 25.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:51<00:00, 25.81s/it]
Device set to use cuda:0
  0%|          | 0/235 [00:00<?, ?it/s]csv_path: results/attacked/evaluation_log_deepseek_7b_negation_objective.csv
  0%|          | 1/235 [00:40<2:38:57, 40.76s/it]  1%|          | 2/235 [07:32<16:45:59, 259.06s/it]  1%|▏         | 3/235 [15:13<22:37:33, 351.09s/it]  2%|▏         | 4/235 [20:21<21:26:54, 334.26s/it]  2%|▏         | 5/235 [30:35<27:48:18, 435.21s/it]  3%|▎         | 6/235 [36:45<26:15:36, 412.82s/it]  3%|▎         | 7/235 [41:41<23:43:46, 374.68s/it]  3%|▎         | 8/235 [43:42<18:31:43, 293.85s/it]  4%|▍         | 9/235 [49:27<19:27:10, 309.87s/it]  4%|▍         | 10/235 [53:12<17:44:20, 283.83s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
