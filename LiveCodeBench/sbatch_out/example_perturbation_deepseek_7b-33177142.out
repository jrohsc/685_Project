/work/pi_ahoumansadr_umass_edu/jroh/miniconda3/envs/overthink/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.76s/it]
Device set to use cuda:0
  0%|          | 0/235 [00:00<?, ?it/s]csv_path: results/attacked/evaluation_log_deepseek_7b_example_perturbation.csv
✅ Resuming from row 1 / 235
  1%|          | 2/235 [07:46<15:04:57, 233.03s/it]  1%|▏         | 3/235 [14:16<19:14:49, 298.66s/it]  2%|▏         | 4/235 [17:51<17:09:23, 267.37s/it]  2%|▏         | 5/235 [24:03<19:24:05, 303.67s/it]  3%|▎         | 6/235 [29:08<19:21:36, 304.35s/it]  3%|▎         | 7/235 [37:48<23:40:04, 373.70s/it]  3%|▎         | 8/235 [38:41<17:11:40, 272.69s/it]  4%|▍         | 9/235 [45:40<19:57:49, 318.01s/it]  4%|▍         | 10/235 [58:20<28:21:13, 453.66s/it]  5%|▍         | 11/235 [1:09:36<32:26:45, 521.45s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  5%|▌         | 12/235 [1:13:03<26:23:55, 426.17s/it]  6%|▌         | 13/235 [1:18:46<24:43:09, 400.85s/it]